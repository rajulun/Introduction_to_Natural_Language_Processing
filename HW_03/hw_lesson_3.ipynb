{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw_lesson_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZknS-LoqJaMa",
        "colab_type": "text"
      },
      "source": [
        "## Тема “Создание признакового пространства”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NJ_EKC1JiaZ",
        "colab_type": "text"
      },
      "source": [
        "### Используем предобработанные в рамках 1-ого домашнего задания датасет combine_df_prepocessed.pkl. Используем столбец 'clean_tweet'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHibqU0fJRyC",
        "colab_type": "text"
      },
      "source": [
        "### Задание 1.\n",
        "1.1 Используя библиотеку Spacy, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? (Учтите, что max_word_limit_spacy для Spacy = 1000000)       \n",
        "1.2 С помощью Spacy выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?\n",
        "Повторим шаги из заданий 1 и 2, используя библиотеку nltk.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMRNe0-KVpf3",
        "colab_type": "text"
      },
      "source": [
        "1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHuIa4Oq4xuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ewf_11F2kvS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "1c469ce4-3b9d-4e8d-d244-28b396616279"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVQyvYOsJsqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "f64325e0-1e3a-487d-eaf5-e704774bb9d5"
      },
      "source": [
        "combine_df = pd.read_pickle('tweet_preprocessed.pkl')\n",
        "combine_df.head(2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "      <th>tweet_stemmed</th>\n",
              "      <th>tweet_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
              "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
              "      <td>[when, father, is, dysfunct, and, is, so, self...</td>\n",
              "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
              "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
              "      <td>[thank, for, lyft, credit, can, not, use, caus...</td>\n",
              "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                   tweet_lemmatized\n",
              "0   1  ...  [when, father, is, dysfunctional, and, is, so,...\n",
              "1   2  ...  [thanks, for, lyft, credit, can, not, use, cau...\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-9FYEkq5uU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "da9333ef-ca94-49c0-a98f-d5de2dea5fc2"
      },
      "source": [
        "train_df = pd.read_csv('train_tweets.csv')\n",
        "train_df.head(2)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBA4JccL5vW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "d944ced2-3217-422a-c4e1-b36fec86a4fe"
      },
      "source": [
        "test_df = pd.read_csv('test_tweets.csv')\n",
        "test_df.head(2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
              "1  31964   @user #white #supremacists want everyone to s..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0pXuwZjA452",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -U spacy\n",
        "#!python -m spacy info\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import en_core_web_md"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YV47ChzK0hP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkAvx_kkO07f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bad1a172-3111-4456-e320-49ab712d4ad4"
      },
      "source": [
        "spacy.cli.download('en_core_web_md')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxrE3yki9luY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_len = train_df.shape[0]\n",
        "test_len = test_df.shape[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpt4uOGUJsfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = en_core_web_md.load()\n",
        "train_text = combine_df.clean_tweet[:train_len].apply(lambda x: nlp(x)).tolist()\n",
        "test_text = combine_df.clean_tweet[train_len:].apply(lambda x: nlp(x)).tolist()\n",
        "combine_text = train_text + test_text\n",
        "\n",
        "# len(text_combine)\n",
        "# article = nlp(text_combine)\n",
        "# displacy.render(article, jupyter=True, style='ent')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YexrStVFHqS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "displacy.render(combine_text, jupyter=True, style='ent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaVXWsxgFVTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "da028551-2281-4152-f161-da02524e118c"
      },
      "source": [
        "len(combine_text) == combine_df.shape[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYEF6uU2LW1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "bf7dce6e-e138-4f4b-b611-4a9ac9853c5d"
      },
      "source": [
        "word_NER = []\n",
        "for doc in combine_text:\n",
        "    for ent in doc.ents:\n",
        "        word_NER.append((ent.text, ent.label_))\n",
        "\n",
        "df_ner = pd.DataFrame(word_NER, columns=['word', 'word_NER'])\n",
        "df_ner.head(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>word_NER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pdx</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>getthanked</td>\n",
              "      <td>PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bihday</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yoyour</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tomorrow</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>danny</td>\n",
              "      <td>PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>the next school year</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the year</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cavs champions cleveland</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ireland</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       word word_NER\n",
              "0                       pdx      GPE\n",
              "1                getthanked   PERSON\n",
              "2                    bihday     DATE\n",
              "3                    yoyour      GPE\n",
              "4                  tomorrow     DATE\n",
              "5                     danny   PERSON\n",
              "6      the next school year     DATE\n",
              "7                  the year     DATE\n",
              "8  cavs champions cleveland      ORG\n",
              "9                   ireland      GPE"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nafXDv8GVOuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1268a66d-2925-4c2c-f9d4-bc9a04f5c41b"
      },
      "source": [
        "df_ner.shape[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN1eK4RomZsD",
        "colab_type": "text"
      },
      "source": [
        "## ТОП-20 популярных NER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEvQdio2GmbH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "2d97b861-e42d-418d-9d1b-0d9169efd0e1"
      },
      "source": [
        "df_ner.word_NER.value_counts().head(20)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PERSON         11639\n",
              "DATE           10584\n",
              "ORG             8305\n",
              "GPE             5862\n",
              "TIME            2223\n",
              "NORP            1711\n",
              "CARDINAL        1062\n",
              "ORDINAL          576\n",
              "FAC              376\n",
              "PRODUCT          305\n",
              "LOC              283\n",
              "EVENT            220\n",
              "WORK_OF_ART      106\n",
              "QUANTITY          54\n",
              "LANGUAGE          36\n",
              "MONEY             19\n",
              "LAW               13\n",
              "PERCENT            4\n",
              "Name: word_NER, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECs1CBshVvFG",
        "colab_type": "text"
      },
      "source": [
        "1.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRKymOLkbIXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_NER = []\n",
        "for doc in train_text:\n",
        "    for ent in doc.ents:\n",
        "        word_NER.append((ent.text, ent.label_))\n",
        "\n",
        "df_train_ner = pd.DataFrame(word_NER, columns=['word', 'word_NER'])\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5tCZoO_bIKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_NER = []\n",
        "for doc in test_text:\n",
        "    for ent in doc.ents:\n",
        "        word_NER.append((ent.text, ent.label_))\n",
        "\n",
        "df_test_ner = pd.DataFrame(word_NER, columns=['word', 'word_NER'])\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOMNG7NebH7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "d8fb25ab-86ac-4457-a359-8365426767d5"
      },
      "source": [
        "df_combine_ner = pd.concat([df_train_ner, df_test_ner], ignore_index=True)\n",
        "\n",
        "df_combine_ner.head(10)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>word_NER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pdx</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>getthanked</td>\n",
              "      <td>PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bihday</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yoyour</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tomorrow</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>danny</td>\n",
              "      <td>PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>the next school year</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the year</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cavs champions cleveland</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ireland</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       word word_NER\n",
              "0                       pdx      GPE\n",
              "1                getthanked   PERSON\n",
              "2                    bihday     DATE\n",
              "3                    yoyour      GPE\n",
              "4                  tomorrow     DATE\n",
              "5                     danny   PERSON\n",
              "6      the next school year     DATE\n",
              "7                  the year     DATE\n",
              "8  cavs champions cleveland      ORG\n",
              "9                   ireland      GPE"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz1TI99Ac9DC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b9e6d62-3f17-4139-a3c9-ed4861b4b053"
      },
      "source": [
        "len(df_combine_ner)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ivERM-rmins",
        "colab_type": "text"
      },
      "source": [
        "## Наиболее обсуждаемые персоны в train датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I71-cHhNaNf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "b1669d2b-f75f-4c95-bf53-1f713ecf14a6"
      },
      "source": [
        "df_train_ner.loc[df_train_ner['word_NER'] == 'PERSON'].word.value_counts().head(20)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bing bong bing bong                                        75\n",
              "obama                                                      45\n",
              "suppo                                                      35\n",
              "hillary                                                    35\n",
              "melancholy melancholymusic                                 31\n",
              "sta                                                        26\n",
              "bjp                                                        23\n",
              "feminismiscancer feminismisterrorism feminismmuktbharat    20\n",
              "hu                                                         18\n",
              "christina grimmie                                          18\n",
              "tgif ff                                                    18\n",
              "sea shepherd suppoers                                      17\n",
              "yoyoyou                                                    17\n",
              "gamedev indiedev indiegamedev                              17\n",
              "heabroken                                                  16\n",
              "lebron                                                     16\n",
              "jo cox                                                     16\n",
              "donald trump                                               15\n",
              "detoxdiet altwaystoheal                                    15\n",
              "boricua                                                    14\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNeZskK-mxZL",
        "colab_type": "text"
      },
      "source": [
        "## Наиболее обсуждаемые персоны в test датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaAzFwBchD3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "b6c605ac-94cd-4e75-f70f-46489eebdd7a"
      },
      "source": [
        "df_test_ner.loc[df_test_ner['word_NER'] == 'PERSON'].word.value_counts().head(20)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bing bong bing bong                                        32\n",
              "suppo                                                      31\n",
              "obama                                                      22\n",
              "feminismiscancer feminismisterrorism feminismmuktbharat    20\n",
              "sta                                                        19\n",
              "hillary                                                    13\n",
              "christina grimmie                                          12\n",
              "bjp                                                        11\n",
              "jo cox                                                     11\n",
              "jesus                                                      10\n",
              "lebron                                                     10\n",
              "regrann                                                    10\n",
              "donald trump                                                9\n",
              "clinton                                                     9\n",
              "melancholy melancholymusic                                  9\n",
              "th bihday                                                   9\n",
              "boricua                                                     8\n",
              "tgif ff                                                     8\n",
              "gamedev indiedev indiegamedev                               8\n",
              "sea shepherd suppoers                                       8\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DbLmA56nFyj",
        "colab_type": "text"
      },
      "source": [
        "## Наиболее обсуждаемые организации в train датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkiFjN1chPm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "c93477fc-3d46-46ab-d424-4d56f79bd73f"
      },
      "source": [
        "df_train_ner.loc[df_train_ner['word_NER'] == 'ORG'].word.value_counts().head(20)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sjw                 73\n",
              "allahsoil           52\n",
              "gop                 51\n",
              "nba                 38\n",
              "islam               34\n",
              "cavs                30\n",
              "social analytics    27\n",
              "ht                  27\n",
              "wso                 26\n",
              "trump               26\n",
              "facebook            25\n",
              "cnn                 24\n",
              "google              21\n",
              "ios                 21\n",
              "bihday              18\n",
              "eu                  17\n",
              "house               15\n",
              "brexit              14\n",
              "obama               14\n",
              "bogota colombia     14\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu-n4IgJm7QG",
        "colab_type": "text"
      },
      "source": [
        "## Наиболее обсуждаемые организации в test датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjsyMkumhSbG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "25131e56-b91b-4511-b5d6-8ed9911621c8"
      },
      "source": [
        "df_test_ner.loc[df_test_ner['word_NER'] == 'ORG'].word.value_counts().head(20)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "allahsoil    31\n",
              "sjw          29\n",
              "gop          25\n",
              "trump        21\n",
              "bihday       20\n",
              "nba          20\n",
              "ht           17\n",
              "islam        16\n",
              "facebook     11\n",
              "obama        11\n",
              "amazon        9\n",
              "eu            9\n",
              "cnn           9\n",
              "cavs          9\n",
              "google        8\n",
              "fbi           8\n",
              "ios           8\n",
              "gbpusd        8\n",
              "vsco          8\n",
              "spo           8\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wwcUxBFGmBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJwpZ1OiJp-v",
        "colab_type": "text"
      },
      "source": [
        "### Задание 2.\n",
        "Используя библиотеку nltk, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? Для данного задания используем ограничение на количество символов во входном датасете (max_word_limit_spacy = 1000000), чтобы иметь возможность сравнить результаты работы Spacy и nltk. Обратите внимание, что nltk чувствителен к регистру.\n",
        "С помощью nltk выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMFC11FWn5no",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c959a46d-9e14-4f1a-9651-13a1ebd3ffce"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gBJ0PfjI-cl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34a84aff-a8fc-4987-81a2-a2ea13ad94ea"
      },
      "source": [
        "document = combine_df.clean_tweet.apply(lambda x: nlp(x)).to_string()\n",
        "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label') }"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxtX9oMfztus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92a8fd68-1a85-4f3e-df80-b39ae1da3194"
      },
      "source": [
        "nltk.pos_tag(nltk.word_tokenize(document))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('0', 'CD'),\n",
              " ('(', '('),\n",
              " ('when', 'WRB'),\n",
              " (',', ','),\n",
              " ('father', 'RB'),\n",
              " (',', ','),\n",
              " ('is', 'VBZ'),\n",
              " (',', ','),\n",
              " ('dysfunctional', 'JJ'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " (',', ','),\n",
              " ('is', 'VBZ'),\n",
              " (',', ','),\n",
              " ('so', 'RB'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('1', 'CD'),\n",
              " ('(', '('),\n",
              " ('thanks', 'NNS'),\n",
              " (',', ','),\n",
              " ('for', 'IN'),\n",
              " (',', ','),\n",
              " ('lyft', 'NN'),\n",
              " (',', ','),\n",
              " ('credit', 'NN'),\n",
              " (',', ','),\n",
              " ('can', 'MD'),\n",
              " (',', ','),\n",
              " ('not', 'RB'),\n",
              " (',', ','),\n",
              " ('use', 'NN'),\n",
              " (',', ','),\n",
              " ('cau', 'NN'),\n",
              " ('...', ':'),\n",
              " ('2', 'CD'),\n",
              " ('(', '('),\n",
              " ('bihday', 'NN'),\n",
              " (',', ','),\n",
              " ('your', 'PRP$'),\n",
              " (',', ','),\n",
              " ('majesty', 'NN'),\n",
              " (')', ')'),\n",
              " ('3', 'CD'),\n",
              " ('(', '('),\n",
              " ('model', 'NN'),\n",
              " (',', ','),\n",
              " ('love', 'VB'),\n",
              " (',', ','),\n",
              " ('yoyou', 'PRP'),\n",
              " (',', ','),\n",
              " ('take', 'VB'),\n",
              " (',', ','),\n",
              " ('with', 'IN'),\n",
              " (',', ','),\n",
              " ('yoyou', 'UH'),\n",
              " (',', ','),\n",
              " ('all', 'DT'),\n",
              " (',', ','),\n",
              " ('t', 'NNS'),\n",
              " ('...', ':'),\n",
              " ('4', 'CD'),\n",
              " ('(', '('),\n",
              " ('factsguide', 'NN'),\n",
              " (',', ','),\n",
              " ('society', 'NN'),\n",
              " (',', ','),\n",
              " ('now', 'RB'),\n",
              " (',', ','),\n",
              " ('motivation', 'NN'),\n",
              " (')', ')'),\n",
              " ('5', 'CD'),\n",
              " ('(', '('),\n",
              " ('huge', 'JJ'),\n",
              " (',', ','),\n",
              " ('fan', 'NN'),\n",
              " (',', ','),\n",
              " ('fare', 'NN'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " (',', ','),\n",
              " ('big', 'JJ'),\n",
              " (',', ','),\n",
              " ('talking', 'VBG'),\n",
              " (',', ','),\n",
              " ('before', 'IN'),\n",
              " (',', ','),\n",
              " ('t', 'NN'),\n",
              " ('...', ':'),\n",
              " ('6', 'CD'),\n",
              " ('(', '('),\n",
              " ('camping', 'NN'),\n",
              " (',', ','),\n",
              " ('tomorrow', 'NN'),\n",
              " (',', ','),\n",
              " ('danny', 'NN'),\n",
              " (')', ')'),\n",
              " ('7', 'CD'),\n",
              " ('(', '('),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('next', 'JJ'),\n",
              " (',', ','),\n",
              " ('school', 'NN'),\n",
              " (',', ','),\n",
              " ('year', 'NN'),\n",
              " (',', ','),\n",
              " ('is', 'VBZ'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('year', 'NN'),\n",
              " (',', ','),\n",
              " ('for', 'IN'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('8', 'CD'),\n",
              " ('(', '('),\n",
              " ('we', 'PRP'),\n",
              " (',', ','),\n",
              " ('won', 'VBD'),\n",
              " (',', ','),\n",
              " ('love', 'NN'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('land', 'NN'),\n",
              " (',', ','),\n",
              " ('allin', 'NN'),\n",
              " (',', ','),\n",
              " ('cavs', 'NN'),\n",
              " (',', ','),\n",
              " ('champi', 'NN'),\n",
              " ('...', ':'),\n",
              " ('9', 'CD'),\n",
              " ('(', '('),\n",
              " ('welcome', 'NN'),\n",
              " (',', ','),\n",
              " ('here', 'RB'),\n",
              " (',', ','),\n",
              " ('am', 'VBP'),\n",
              " (',', ','),\n",
              " ('it', 'PRP'),\n",
              " (',', ','),\n",
              " ('has', 'VBZ'),\n",
              " (',', ','),\n",
              " ('it', 'PRP'),\n",
              " (',', ','),\n",
              " ('is', 'VBZ'),\n",
              " (',', ','),\n",
              " ('so', 'RB'),\n",
              " (',', ','),\n",
              " ('gr', 'NN'),\n",
              " (')', ')'),\n",
              " ('10', 'CD'),\n",
              " ('(', '('),\n",
              " ('ireland', 'NN'),\n",
              " (',', ','),\n",
              " ('consumer', 'NN'),\n",
              " (',', ','),\n",
              " ('price', 'NN'),\n",
              " (',', ','),\n",
              " ('index', 'NN'),\n",
              " (',', ','),\n",
              " ('mom', 'NN'),\n",
              " (',', ','),\n",
              " ('climbed', 'VBD'),\n",
              " ('...', ':'),\n",
              " ('11', 'CD'),\n",
              " ('(', '('),\n",
              " ('we', 'PRP'),\n",
              " (',', ','),\n",
              " ('are', 'VBP'),\n",
              " (',', ','),\n",
              " ('so', 'RB'),\n",
              " (',', ','),\n",
              " ('selfish', 'JJ'),\n",
              " (',', ','),\n",
              " ('orlando', 'JJ'),\n",
              " (',', ','),\n",
              " ('standwithorlan', 'NN'),\n",
              " ('...', ':'),\n",
              " ('12', 'CD'),\n",
              " ('(', '('),\n",
              " ('get', 'VB'),\n",
              " (',', ','),\n",
              " ('to', 'TO'),\n",
              " (',', ','),\n",
              " ('see', 'VB'),\n",
              " (',', ','),\n",
              " ('my', 'PRP$'),\n",
              " (',', ','),\n",
              " ('daddy', 'NN'),\n",
              " (',', ','),\n",
              " ('today', 'NN'),\n",
              " (',', ','),\n",
              " ('days', 'NNS'),\n",
              " (',', ','),\n",
              " ('getting', 'VBG'),\n",
              " ('...', ':'),\n",
              " ('13', 'CD'),\n",
              " ('(', '('),\n",
              " ('cnn', 'NN'),\n",
              " (',', ','),\n",
              " ('calls', 'VBZ'),\n",
              " (',', ','),\n",
              " ('michigan', 'FW'),\n",
              " (',', ','),\n",
              " ('middle', 'FW'),\n",
              " (',', ','),\n",
              " ('school', 'NN'),\n",
              " (',', ','),\n",
              " ('build', 'NN'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('14', 'CD'),\n",
              " ('(', '('),\n",
              " ('no', 'DT'),\n",
              " (',', ','),\n",
              " ('comment', 'NN'),\n",
              " (',', ','),\n",
              " ('in', 'IN'),\n",
              " (',', ','),\n",
              " ('australia', 'NN'),\n",
              " (',', ','),\n",
              " ('opkillingbay', 'NN'),\n",
              " (',', ','),\n",
              " ('sea', 'NN'),\n",
              " ('...', ':'),\n",
              " ('15', 'CD'),\n",
              " ('(', '('),\n",
              " ('ouch', 'JJ'),\n",
              " (',', ','),\n",
              " ('junior', 'JJ'),\n",
              " (',', ','),\n",
              " ('is', 'VBZ'),\n",
              " (',', ','),\n",
              " ('angrygot', 'RB'),\n",
              " (',', ','),\n",
              " ('junior', 'JJ'),\n",
              " (',', ','),\n",
              " ('yugyoem', 'RB'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('16', 'CD'),\n",
              " ('(', '('),\n",
              " ('am', 'VBP'),\n",
              " (',', ','),\n",
              " ('thankful', 'JJ'),\n",
              " (',', ','),\n",
              " ('for', 'IN'),\n",
              " (',', ','),\n",
              " ('having', 'VBG'),\n",
              " (',', ','),\n",
              " ('paner', 'NN'),\n",
              " (',', ','),\n",
              " ('thankful', 'JJ'),\n",
              " (',', ','),\n",
              " ('p', 'NN'),\n",
              " ('...', ':'),\n",
              " ('17', 'CD'),\n",
              " ('(', '('),\n",
              " ('retweet', 'NN'),\n",
              " (',', ','),\n",
              " ('if', 'IN'),\n",
              " (',', ','),\n",
              " ('you', 'PRP'),\n",
              " (',', ','),\n",
              " ('agree', 'VBP'),\n",
              " (')', ')'),\n",
              " ('18', 'CD'),\n",
              " ('(', '('),\n",
              " ('its', 'PRP$'),\n",
              " (',', ','),\n",
              " ('friday', 'NN'),\n",
              " (',', ','),\n",
              " ('smiles', 'NNS'),\n",
              " (',', ','),\n",
              " ('all', 'DT'),\n",
              " (',', ','),\n",
              " ('around', 'IN'),\n",
              " (',', ','),\n",
              " ('via', 'IN'),\n",
              " (',', ','),\n",
              " ('ig', 'NN'),\n",
              " (',', ','),\n",
              " ('us', 'PRP'),\n",
              " ('...', ':'),\n",
              " ('19', 'CD'),\n",
              " ('(', '('),\n",
              " ('as', 'IN'),\n",
              " (',', ','),\n",
              " ('we', 'PRP'),\n",
              " (',', ','),\n",
              " ('all', 'DT'),\n",
              " (',', ','),\n",
              " ('know', 'VBP'),\n",
              " (',', ','),\n",
              " ('essential', 'JJ'),\n",
              " (',', ','),\n",
              " ('oils', 'NNS'),\n",
              " (',', ','),\n",
              " ('are', 'VBP'),\n",
              " (',', ','),\n",
              " ('not', 'RB'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('20', 'CD'),\n",
              " ('(', '('),\n",
              " ('euro', 'NN'),\n",
              " (',', ','),\n",
              " ('people', 'NNS'),\n",
              " (',', ','),\n",
              " ('blaming', 'VBG'),\n",
              " (',', ','),\n",
              " ('ha', 'NN'),\n",
              " (',', ','),\n",
              " ('for', 'IN'),\n",
              " (',', ','),\n",
              " ('conceded', 'VBD'),\n",
              " (',', ','),\n",
              " ('goa', 'NN'),\n",
              " ('...', ':'),\n",
              " ('21', 'CD'),\n",
              " ('(', '('),\n",
              " ('sad', 'JJ'),\n",
              " (',', ','),\n",
              " ('little', 'JJ'),\n",
              " (',', ','),\n",
              " ('dude', 'NN'),\n",
              " (',', ','),\n",
              " ('badday', 'NN'),\n",
              " (',', ','),\n",
              " ('coneofshame', 'NN'),\n",
              " (',', ','),\n",
              " ('cats', 'NNS'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('22', 'CD'),\n",
              " ('(', '('),\n",
              " ('product', 'NN'),\n",
              " (',', ','),\n",
              " ('of', 'IN'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('day', 'NN'),\n",
              " (',', ','),\n",
              " ('happy', 'JJ'),\n",
              " (',', ','),\n",
              " ('man', 'NN'),\n",
              " (',', ','),\n",
              " ('wine', 'NN'),\n",
              " (',', ','),\n",
              " ('tool', 'NN'),\n",
              " ('...', ':'),\n",
              " ('23', 'CD'),\n",
              " ('(', '('),\n",
              " ('lumpy', 'NN'),\n",
              " (',', ','),\n",
              " ('says', 'VBZ'),\n",
              " (',', ','),\n",
              " ('am', 'VBP'),\n",
              " (',', ','),\n",
              " ('prove', 'VBP'),\n",
              " (',', ','),\n",
              " ('it', 'PRP'),\n",
              " (',', ','),\n",
              " ('lumpy', 'VBZ'),\n",
              " (')', ')'),\n",
              " ('24', 'CD'),\n",
              " ('(', '('),\n",
              " ('tgif', 'NN'),\n",
              " (',', ','),\n",
              " ('ff', 'NN'),\n",
              " (',', ','),\n",
              " ('to', 'TO'),\n",
              " (',', ','),\n",
              " ('my', 'PRP$'),\n",
              " (',', ','),\n",
              " ('gamedev', 'NN'),\n",
              " (',', ','),\n",
              " ('indiedev', 'NN'),\n",
              " (',', ','),\n",
              " ('indiegam', 'NN'),\n",
              " ('...', ':'),\n",
              " ('25', 'CD'),\n",
              " ('(', '('),\n",
              " ('beautiful', 'JJ'),\n",
              " (',', ','),\n",
              " ('sign', 'NN'),\n",
              " (',', ','),\n",
              " ('by', 'IN'),\n",
              " (',', ','),\n",
              " ('vendor', 'NN'),\n",
              " (',', ','),\n",
              " ('for', 'IN'),\n",
              " (',', ','),\n",
              " ('upsideofflo', 'JJ'),\n",
              " ('...', ':'),\n",
              " ('26', 'CD'),\n",
              " ('(', '('),\n",
              " ('all', 'DT'),\n",
              " (',', ','),\n",
              " ('smiles', 'NNS'),\n",
              " (',', ','),\n",
              " ('when', 'WRB'),\n",
              " (',', ','),\n",
              " ('media', 'NNS'),\n",
              " (',', ','),\n",
              " ('is', 'VBZ'),\n",
              " (',', ','),\n",
              " ('pressconference', 'NN'),\n",
              " ('...', ':'),\n",
              " ('27', 'CD'),\n",
              " ('(', '('),\n",
              " ('we', 'PRP'),\n",
              " (',', ','),\n",
              " ('had', 'VBD'),\n",
              " (',', ','),\n",
              " ('great', 'JJ'),\n",
              " (',', ','),\n",
              " ('panel', 'NN'),\n",
              " (',', ','),\n",
              " ('on', 'IN'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('mediatization', 'NN'),\n",
              " ('...', ':'),\n",
              " ('28', 'CD'),\n",
              " ('(', '('),\n",
              " ('happy', 'JJ'),\n",
              " (',', ','),\n",
              " ('fathers', 'NNS'),\n",
              " (',', ','),\n",
              " ('day', 'NN'),\n",
              " (')', ')'),\n",
              " ('29', 'CD'),\n",
              " ('(', '('),\n",
              " ('people', 'NNS'),\n",
              " (',', ','),\n",
              " ('went', 'VBD'),\n",
              " (',', ','),\n",
              " ('to', 'TO'),\n",
              " (',', ','),\n",
              " ('nightclub', 'RB'),\n",
              " (',', ','),\n",
              " ('to', 'TO'),\n",
              " (',', ','),\n",
              " ('have', 'VB'),\n",
              " (',', ','),\n",
              " ('good', 'JJ'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('30', 'CD'),\n",
              " ('(', '('),\n",
              " ('have', 'VB'),\n",
              " (',', ','),\n",
              " ('never', 'RB'),\n",
              " (',', ','),\n",
              " ('had', 'VBD'),\n",
              " (',', ','),\n",
              " ('chance', 'NN'),\n",
              " (',', ','),\n",
              " ('to', 'TO'),\n",
              " (',', ','),\n",
              " ('vote', 'NN'),\n",
              " (',', ','),\n",
              " ('for', 'IN'),\n",
              " (',', ','),\n",
              " ('pres', 'NNS'),\n",
              " ('...', ':'),\n",
              " ('31', 'CD'),\n",
              " ('(', '('),\n",
              " ('alohafriday', 'NN'),\n",
              " (',', ','),\n",
              " ('time', 'NN'),\n",
              " (',', ','),\n",
              " ('does', 'VBZ'),\n",
              " (',', ','),\n",
              " ('not', 'RB'),\n",
              " (',', ','),\n",
              " ('exist', 'VBP'),\n",
              " (',', ','),\n",
              " ('positive', 'JJ'),\n",
              " ('...', ':'),\n",
              " ('32', 'CD'),\n",
              " ('(', '('),\n",
              " ('rip', 'NN'),\n",
              " (',', ','),\n",
              " ('to', 'TO'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('fellow', 'NN'),\n",
              " (',', ','),\n",
              " ('nohern', 'JJ'),\n",
              " (',', ','),\n",
              " ('ireland', 'NN'),\n",
              " (',', ','),\n",
              " ('fan', 'NN'),\n",
              " (',', ','),\n",
              " ('w', 'NN'),\n",
              " ('...', ':'),\n",
              " ('33', 'CD'),\n",
              " ('(', '('),\n",
              " ('it', 'PRP'),\n",
              " (',', ','),\n",
              " ('was', 'VBD'),\n",
              " (',', ','),\n",
              " ('hard', 'JJ'),\n",
              " (',', ','),\n",
              " ('monday', 'JJ'),\n",
              " (',', ','),\n",
              " ('due', 'JJ'),\n",
              " (',', ','),\n",
              " ('to', 'TO'),\n",
              " (',', ','),\n",
              " ('cloudy', 'NN'),\n",
              " (',', ','),\n",
              " ('weath', 'NN'),\n",
              " ('...', ':'),\n",
              " ('34', 'CD'),\n",
              " ('(', '('),\n",
              " ('it', 'PRP'),\n",
              " (',', ','),\n",
              " ('has', 'VBZ'),\n",
              " (',', ','),\n",
              " ('it', 'PRP'),\n",
              " (',', ','),\n",
              " ('is', 'VBZ'),\n",
              " (',', ','),\n",
              " ('unbelievable', 'JJ'),\n",
              " (',', ','),\n",
              " ('that', 'DT'),\n",
              " (',', ','),\n",
              " ('in', 'IN'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('35', 'CD'),\n",
              " ('(', '('),\n",
              " ('taylorswift', 'NN'),\n",
              " (',', ','),\n",
              " ('bull', 'NN'),\n",
              " (',', ','),\n",
              " ('up', 'RB'),\n",
              " (',', ','),\n",
              " ('you', 'PRP'),\n",
              " (',', ','),\n",
              " ('will', 'MD'),\n",
              " (',', ','),\n",
              " ('dominate', 'VB'),\n",
              " (',', ','),\n",
              " ('y', 'VB'),\n",
              " ('...', ':'),\n",
              " ('36', 'CD'),\n",
              " ('(', '('),\n",
              " ('morning', 'NN'),\n",
              " (',', ','),\n",
              " ('travelingram', 'NN'),\n",
              " (',', ','),\n",
              " ('dalat', 'NN'),\n",
              " (',', ','),\n",
              " ('ripinkylife', 'NN'),\n",
              " (')', ')'),\n",
              " ('37', 'CD'),\n",
              " ('(', '('),\n",
              " ('once', 'RB'),\n",
              " (',', ','),\n",
              " ('more', 'JJR'),\n",
              " (',', ','),\n",
              " ('only', 'RB'),\n",
              " (',', ','),\n",
              " ('one', 'CD'),\n",
              " (',', ','),\n",
              " ('word', 'NN'),\n",
              " (',', ','),\n",
              " ('tells', 'NNS'),\n",
              " (',', ','),\n",
              " ('it', 'PRP'),\n",
              " (',', ','),\n",
              " ('all', 'DT'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('38', 'CD'),\n",
              " ('(', '('),\n",
              " ('oh', 'UH'),\n",
              " (',', ','),\n",
              " ('cedarpoint', 'NN'),\n",
              " (',', ','),\n",
              " ('waited', 'VBD'),\n",
              " (',', ','),\n",
              " ('hours', 'NNS'),\n",
              " (',', ','),\n",
              " ('in', 'IN'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('valra', 'NN'),\n",
              " ('...', ':'),\n",
              " ('39', 'CD'),\n",
              " ('(', '('),\n",
              " ('am', 'VBP'),\n",
              " (',', ','),\n",
              " ('thankful', 'JJ'),\n",
              " (',', ','),\n",
              " ('for', 'IN'),\n",
              " (',', ','),\n",
              " ('sunshine', 'NN'),\n",
              " (',', ','),\n",
              " ('thankful', 'JJ'),\n",
              " (',', ','),\n",
              " ('positive', 'JJ'),\n",
              " (')', ')'),\n",
              " ('40', 'CD'),\n",
              " ('(', '('),\n",
              " ('when', 'WRB'),\n",
              " (',', ','),\n",
              " ('you', 'PRP'),\n",
              " (',', ','),\n",
              " ('finally', 'RB'),\n",
              " (',', ','),\n",
              " ('finish', 'JJ'),\n",
              " (',', ','),\n",
              " ('book', 'NN'),\n",
              " (',', ','),\n",
              " ('you', 'PRP'),\n",
              " (',', ','),\n",
              " ('have', 'VBP'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('41', 'CD'),\n",
              " ('(', '('),\n",
              " ('yup', 'NN'),\n",
              " (',', ','),\n",
              " ('being', 'VBG'),\n",
              " (',', ','),\n",
              " ('knicks', 'NNS'),\n",
              " (',', ','),\n",
              " ('fan', 'NN'),\n",
              " (',', ','),\n",
              " ('is', 'VBZ'),\n",
              " (',', ','),\n",
              " ('hard', 'RB'),\n",
              " (',', ','),\n",
              " ('so', 'RB'),\n",
              " (',', ','),\n",
              " ('its', 'PRP$'),\n",
              " (',', ','),\n",
              " ('e', 'NN'),\n",
              " ('...', ':'),\n",
              " ('42', 'CD'),\n",
              " ('(', '('),\n",
              " ('there', 'RB'),\n",
              " (',', ','),\n",
              " ('is', 'VBZ'),\n",
              " (',', ','),\n",
              " ('life', 'NN'),\n",
              " (',', ','),\n",
              " ('after', 'IN'),\n",
              " (',', ','),\n",
              " ('social', 'JJ'),\n",
              " (',', ','),\n",
              " ('networking', 'JJ'),\n",
              " (',', ','),\n",
              " ('e', 'NN'),\n",
              " ('...', ':'),\n",
              " ('43', 'CD'),\n",
              " ('(', '('),\n",
              " ('my', 'PRP$'),\n",
              " (',', ','),\n",
              " ('mom', 'NN'),\n",
              " (',', ','),\n",
              " ('shares', 'NNS'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('same', 'JJ'),\n",
              " (',', ','),\n",
              " ('bihday', 'RB'),\n",
              " (',', ','),\n",
              " ('as', 'IN'),\n",
              " (',', ','),\n",
              " ('bihda', 'NN'),\n",
              " ('...', ':'),\n",
              " ('44', 'CD'),\n",
              " ('(', '('),\n",
              " ('lovely', 'RB'),\n",
              " (',', ','),\n",
              " ('echeveria', 'NNS'),\n",
              " (',', ','),\n",
              " ('bloomsflowers', 'NNS'),\n",
              " (',', ','),\n",
              " ('grow', 'NN'),\n",
              " (',', ','),\n",
              " ('garde', 'NN'),\n",
              " ('...', ':'),\n",
              " ('45', 'CD'),\n",
              " ('(', '('),\n",
              " ('am', 'VBP'),\n",
              " (',', ','),\n",
              " ('amazing', 'JJ'),\n",
              " (',', ','),\n",
              " ('iam', 'JJ'),\n",
              " (',', ','),\n",
              " ('positive', 'JJ'),\n",
              " (',', ','),\n",
              " ('affirmation', 'NN'),\n",
              " (')', ')'),\n",
              " ('46', 'CD'),\n",
              " ('(', '('),\n",
              " ('model', 'NN'),\n",
              " (',', ','),\n",
              " ('love', 'VB'),\n",
              " (',', ','),\n",
              " ('yoyou', 'PRP'),\n",
              " (',', ','),\n",
              " ('take', 'VB'),\n",
              " (',', ','),\n",
              " ('with', 'IN'),\n",
              " (',', ','),\n",
              " ('yoyou', 'UH'),\n",
              " (',', ','),\n",
              " ('all', 'DT'),\n",
              " (',', ','),\n",
              " ('t', 'NNS'),\n",
              " ('...', ':'),\n",
              " ('47', 'CD'),\n",
              " ('(', '('),\n",
              " ('whenever', 'NN'),\n",
              " (',', ','),\n",
              " ('i', 'NN'),\n",
              " (',', ','),\n",
              " ('m', 'NN'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " (',', ','),\n",
              " ('something', 'NN'),\n",
              " (',', ','),\n",
              " ('goes', 'VBZ'),\n",
              " (',', ','),\n",
              " ('wrong', 'JJ'),\n",
              " (')', ')'),\n",
              " ('48', 'CD'),\n",
              " ('(', '('),\n",
              " ('feeling', 'NN'),\n",
              " (',', ','),\n",
              " ('blue', 'NN'),\n",
              " (',', ','),\n",
              " ('illustration', 'NN'),\n",
              " (')', ')'),\n",
              " ('49', 'CD'),\n",
              " ('(', '('),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('best', 'JJS'),\n",
              " (',', ','),\n",
              " ('pa', 'NN'),\n",
              " (',', ','),\n",
              " ('about', 'RB'),\n",
              " (',', ','),\n",
              " ('life', 'NN'),\n",
              " (',', ','),\n",
              " ('is', 'VBZ'),\n",
              " (',', ','),\n",
              " ('knowing', 'VBG'),\n",
              " (',', ','),\n",
              " ('who', 'WP'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('50', 'CD'),\n",
              " ('(', '('),\n",
              " ('abc', 'NN'),\n",
              " (',', ','),\n",
              " ('getting', 'VBG'),\n",
              " (',', ','),\n",
              " ('ready', 'JJ'),\n",
              " (',', ','),\n",
              " ('remove', 'VB'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('victums', 'NNS'),\n",
              " (',', ','),\n",
              " ('fr', 'NN'),\n",
              " ('...', ':'),\n",
              " ('51', 'CD'),\n",
              " ('(', '('),\n",
              " ('for', 'IN'),\n",
              " (',', ','),\n",
              " ('her', 'PRP'),\n",
              " (',', ','),\n",
              " ('bihday', 'RB'),\n",
              " (',', ','),\n",
              " ('we', 'PRP'),\n",
              " (',', ','),\n",
              " ('got', 'VBD'),\n",
              " (',', ','),\n",
              " ('her', 'PRP'),\n",
              " (',', ','),\n",
              " ('nose', 'RB'),\n",
              " (',', ','),\n",
              " ('job', 'NN'),\n",
              " (',', ','),\n",
              " ('bi', 'NN'),\n",
              " ('...', ':'),\n",
              " ('52', 'CD'),\n",
              " ('(', '('),\n",
              " ('off', 'RB'),\n",
              " (',', ','),\n",
              " ('to', 'TO'),\n",
              " (',', ','),\n",
              " ('concelebrate', 'VB'),\n",
              " (',', ','),\n",
              " ('at', 'IN'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('albanpilgrima', 'NN'),\n",
              " ('...', ':'),\n",
              " ('53', 'CD'),\n",
              " ('(', '('),\n",
              " ('let', 'NN'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('scumbaggery', 'NN'),\n",
              " (',', ','),\n",
              " ('begin', 'NN'),\n",
              " (')', ')'),\n",
              " ('54', 'CD'),\n",
              " ('(', '('),\n",
              " ('thank', 'NN'),\n",
              " (',', ','),\n",
              " ('you', 'PRP'),\n",
              " (',', ','),\n",
              " ('super', 'JJR'),\n",
              " (',', ','),\n",
              " ('love', 'NN'),\n",
              " (',', ','),\n",
              " ('it', 'PRP'),\n",
              " (',', ','),\n",
              " ('zpamdelacruz', 'RB'),\n",
              " (',', ','),\n",
              " ('we', 'PRP'),\n",
              " ('...', ':'),\n",
              " ('55', 'CD'),\n",
              " ('(', '('),\n",
              " ('scourge', 'NN'),\n",
              " (',', ','),\n",
              " ('on', 'IN'),\n",
              " (',', ','),\n",
              " ('those', 'DT'),\n",
              " (',', ','),\n",
              " ('playing', 'VBG'),\n",
              " (',', ','),\n",
              " ('baroque', 'NN'),\n",
              " (',', ','),\n",
              " ('pieces', 'NNS'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('56', 'CD'),\n",
              " ('(', '('),\n",
              " ('lets', 'NNS'),\n",
              " (',', ','),\n",
              " ('fight', 'NN'),\n",
              " (',', ','),\n",
              " ('against', 'IN'),\n",
              " (',', ','),\n",
              " ('love', 'VB'),\n",
              " (',', ','),\n",
              " ('peace', 'NN'),\n",
              " (')', ')'),\n",
              " ('57', 'CD'),\n",
              " ('(', '('),\n",
              " ('happy', 'JJ'),\n",
              " (',', ','),\n",
              " ('fathers', 'NNS'),\n",
              " (',', ','),\n",
              " ('day', 'NN'),\n",
              " (',', ','),\n",
              " ('mr', 'NN'),\n",
              " (',', ','),\n",
              " ('rayos', 'NN'),\n",
              " (',', ','),\n",
              " ('video', 'NN'),\n",
              " (',', ','),\n",
              " ('father', 'NN'),\n",
              " ('...', ':'),\n",
              " ('58', 'CD'),\n",
              " ('(', '('),\n",
              " ('ascot', 'NN'),\n",
              " (',', ','),\n",
              " ('times', 'NNS'),\n",
              " (',', ','),\n",
              " ('with', 'IN'),\n",
              " (',', ','),\n",
              " ('this', 'DT'),\n",
              " (',', ','),\n",
              " ('babe', 'NN'),\n",
              " (',', ','),\n",
              " ('ascot', 'NN'),\n",
              " (',', ','),\n",
              " ('fashio', 'NN'),\n",
              " ('...', ':'),\n",
              " ('59', 'CD'),\n",
              " ('(', '('),\n",
              " ('the', 'DT'),\n",
              " (',', ','),\n",
              " ('weekend', 'NN'),\n",
              " (',', ','),\n",
              " ('is', 'VBZ'),\n",
              " (',', ','),\n",
              " ('here', 'RB'),\n",
              " (',', ','),\n",
              " ('selfie', 'NN'),\n",
              " (',', ','),\n",
              " ('yolo', 'NN'),\n",
              " (',', ','),\n",
              " ('xoxo', 'NNP'),\n",
              " (',', ','),\n",
              " ('l', 'NN'),\n",
              " ('...', ':'),\n",
              " ('60', 'CD'),\n",
              " ('(', '('),\n",
              " ('happy', 'JJ'),\n",
              " (',', ','),\n",
              " ('at', 'IN'),\n",
              " (',', ','),\n",
              " ('work', 'NN'),\n",
              " (',', ','),\n",
              " ('conference', 'NN'),\n",
              " (',', ','),\n",
              " ('right', 'RB'),\n",
              " (',', ','),\n",
              " ('mindset', 'NN'),\n",
              " (',', ','),\n",
              " ('...', ':'),\n",
              " ('61', 'CD'),\n",
              " ('(', '('),\n",
              " ('christina', 'NN'),\n",
              " (',', ','),\n",
              " ('grimmies', 'NNS'),\n",
              " (',', ','),\n",
              " ('last', 'JJ'),\n",
              " (',', ','),\n",
              " ('performance', 'NN'),\n",
              " (',', ','),\n",
              " ('befor', 'NN'),\n",
              " ('...', ':'),\n",
              " ('62', 'CD'),\n",
              " ('(', '('),\n",
              " ('we', 'PRP'),\n",
              " (',', ','),\n",
              " ('are', 'VBP'),\n",
              " (',', ','),\n",
              " ('ready', 'JJ'),\n",
              " (',', ','),\n",
              " ('to', 'TO'),\n",
              " (',', ','),\n",
              " ('dance', 'NN'),\n",
              " (',', ','),\n",
              " ('roar', 'NN'),\n",
              " (',', ','),\n",
              " ('preschoolers', 'NNS'),\n",
              " ('...', ':'),\n",
              " ('63', 'CD'),\n",
              " ('(', '('),\n",
              " ('you', 'PRP'),\n",
              " (',', ','),\n",
              " ('have', 'VBP'),\n",
              " (',', ','),\n",
              " ('really', 'RB'),\n",
              " (',', ','),\n",
              " ('hu', 'NN'),\n",
              " (',', ','),\n",
              " ('my', 'PRP$'),\n",
              " (',', ','),\n",
              " ('feelings', 'NNS'),\n",
              " (')', ')'),\n",
              " ('64', 'CD'),\n",
              " ('(', '('),\n",
              " ('my', 'PRP$'),\n",
              " (',', ','),\n",
              " ('wife', 'NN'),\n",
              " (',', ','),\n",
              " ('whom', 'WP'),\n",
              " (',', ','),\n",
              " ('adore', 'RB'),\n",
              " (',', ','),\n",
              " ('had', 'VBD'),\n",
              " (',', ','),\n",
              " ('to', 'TO'),\n",
              " (',', ','),\n",
              " ('miss', 'VB'),\n",
              " (',', ','),\n",
              " ('your', 'PRP$'),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMOLGylZJvVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZdRRvriJvOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5XCWrWqLPsQ",
        "colab_type": "text"
      },
      "source": [
        "### Задание 3.\n",
        "Какая из библиотек по вашему лучше отработала? Сравните качество полученных most_common NER и количество распознаных NER.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0BygxxHLSrh",
        "colab_type": "text"
      },
      "source": [
        "У NLTK очень плохой результат"
      ]
    }
  ]
}