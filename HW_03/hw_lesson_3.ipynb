{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw_lesson_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZknS-LoqJaMa",
        "colab_type": "text"
      },
      "source": [
        "## Тема “Создание признакового пространства”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NJ_EKC1JiaZ",
        "colab_type": "text"
      },
      "source": [
        "### Используем предобработанные в рамках 1-ого домашнего задания датасет combine_df_prepocessed.pkl. Используем столбец 'clean_tweet'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHibqU0fJRyC",
        "colab_type": "text"
      },
      "source": [
        "### Задание 1.\n",
        "1.1 Используя библиотеку Spacy, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? (Учтите, что max_word_limit_spacy для Spacy = 1000000)       \n",
        "1.2 С помощью Spacy выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?\n",
        "Повторим шаги из заданий 1 и 2, используя библиотеку nltk.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMRNe0-KVpf3",
        "colab_type": "text"
      },
      "source": [
        "1.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHuIa4Oq4xuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ewf_11F2kvS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "1c469ce4-3b9d-4e8d-d244-28b396616279"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVQyvYOsJsqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "f64325e0-1e3a-487d-eaf5-e704774bb9d5"
      },
      "source": [
        "combine_df = pd.read_pickle('tweet_preprocessed.pkl')\n",
        "combine_df.head(2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "      <th>tweet_stemmed</th>\n",
              "      <th>tweet_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>when father is dysfunctional and is so selfish...</td>\n",
              "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
              "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
              "      <td>[when, father, is, dysfunct, and, is, so, self...</td>\n",
              "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
              "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
              "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
              "      <td>[thank, for, lyft, credit, can, not, use, caus...</td>\n",
              "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                   tweet_lemmatized\n",
              "0   1  ...  [when, father, is, dysfunctional, and, is, so,...\n",
              "1   2  ...  [thanks, for, lyft, credit, can, not, use, cau...\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-9FYEkq5uU_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "da9333ef-ca94-49c0-a98f-d5de2dea5fc2"
      },
      "source": [
        "train_df = pd.read_csv('train_tweets.csv')\n",
        "train_df.head(2)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBA4JccL5vW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "d944ced2-3217-422a-c4e1-b36fec86a4fe"
      },
      "source": [
        "test_df = pd.read_csv('test_tweets.csv')\n",
        "test_df.head(2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
              "1  31964   @user #white #supremacists want everyone to s..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0pXuwZjA452",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -U spacy\n",
        "#!python -m spacy info\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import en_core_web_md"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YV47ChzK0hP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkAvx_kkO07f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bad1a172-3111-4456-e320-49ab712d4ad4"
      },
      "source": [
        "spacy.cli.download('en_core_web_md')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxrE3yki9luY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_len = train_df.shape[0]\n",
        "test_len = test_df.shape[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpt4uOGUJsfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = en_core_web_md.load()\n",
        "train_text = combine_df.clean_tweet[:train_len].apply(lambda x: nlp(x)).tolist()\n",
        "test_text = combine_df.clean_tweet[train_len:].apply(lambda x: nlp(x)).tolist()\n",
        "combine_text = train_text + test_text\n",
        "\n",
        "# len(text_combine)\n",
        "# article = nlp(text_combine)\n",
        "# displacy.render(article, jupyter=True, style='ent')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YexrStVFHqS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "displacy.render(combine_text, jupyter=True, style='ent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaVXWsxgFVTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "da028551-2281-4152-f161-da02524e118c"
      },
      "source": [
        "len(combine_text) == combine_df.shape[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYEF6uU2LW1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "bf7dce6e-e138-4f4b-b611-4a9ac9853c5d"
      },
      "source": [
        "word_NER = []\n",
        "for doc in combine_text:\n",
        "    for ent in doc.ents:\n",
        "        word_NER.append((ent.text, ent.label_))\n",
        "\n",
        "df_ner = pd.DataFrame(word_NER, columns=['word', 'word_NER'])\n",
        "df_ner.head(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>word_NER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pdx</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>getthanked</td>\n",
              "      <td>PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bihday</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yoyour</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tomorrow</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>danny</td>\n",
              "      <td>PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>the next school year</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the year</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cavs champions cleveland</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ireland</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       word word_NER\n",
              "0                       pdx      GPE\n",
              "1                getthanked   PERSON\n",
              "2                    bihday     DATE\n",
              "3                    yoyour      GPE\n",
              "4                  tomorrow     DATE\n",
              "5                     danny   PERSON\n",
              "6      the next school year     DATE\n",
              "7                  the year     DATE\n",
              "8  cavs champions cleveland      ORG\n",
              "9                   ireland      GPE"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nafXDv8GVOuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1268a66d-2925-4c2c-f9d4-bc9a04f5c41b"
      },
      "source": [
        "df_ner.shape[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN1eK4RomZsD",
        "colab_type": "text"
      },
      "source": [
        "## ТОП-20 популярных NER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEvQdio2GmbH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "2d97b861-e42d-418d-9d1b-0d9169efd0e1"
      },
      "source": [
        "df_ner.word_NER.value_counts().head(20)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PERSON         11639\n",
              "DATE           10584\n",
              "ORG             8305\n",
              "GPE             5862\n",
              "TIME            2223\n",
              "NORP            1711\n",
              "CARDINAL        1062\n",
              "ORDINAL          576\n",
              "FAC              376\n",
              "PRODUCT          305\n",
              "LOC              283\n",
              "EVENT            220\n",
              "WORK_OF_ART      106\n",
              "QUANTITY          54\n",
              "LANGUAGE          36\n",
              "MONEY             19\n",
              "LAW               13\n",
              "PERCENT            4\n",
              "Name: word_NER, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECs1CBshVvFG",
        "colab_type": "text"
      },
      "source": [
        "1.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRKymOLkbIXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_NER = []\n",
        "for doc in train_text:\n",
        "    for ent in doc.ents:\n",
        "        word_NER.append((ent.text, ent.label_))\n",
        "\n",
        "df_train_ner = pd.DataFrame(word_NER, columns=['word', 'word_NER'])\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5tCZoO_bIKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_NER = []\n",
        "for doc in test_text:\n",
        "    for ent in doc.ents:\n",
        "        word_NER.append((ent.text, ent.label_))\n",
        "\n",
        "df_test_ner = pd.DataFrame(word_NER, columns=['word', 'word_NER'])\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOMNG7NebH7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "d8fb25ab-86ac-4457-a359-8365426767d5"
      },
      "source": [
        "df_combine_ner = pd.concat([df_train_ner, df_test_ner], ignore_index=True)\n",
        "\n",
        "df_combine_ner.head(10)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>word_NER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pdx</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>getthanked</td>\n",
              "      <td>PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bihday</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yoyour</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tomorrow</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>danny</td>\n",
              "      <td>PERSON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>the next school year</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the year</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cavs champions cleveland</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ireland</td>\n",
              "      <td>GPE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       word word_NER\n",
              "0                       pdx      GPE\n",
              "1                getthanked   PERSON\n",
              "2                    bihday     DATE\n",
              "3                    yoyour      GPE\n",
              "4                  tomorrow     DATE\n",
              "5                     danny   PERSON\n",
              "6      the next school year     DATE\n",
              "7                  the year     DATE\n",
              "8  cavs champions cleveland      ORG\n",
              "9                   ireland      GPE"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz1TI99Ac9DC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b9e6d62-3f17-4139-a3c9-ed4861b4b053"
      },
      "source": [
        "len(df_combine_ner)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ivERM-rmins",
        "colab_type": "text"
      },
      "source": [
        "## Наиболее обсуждаемые персоны в train датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I71-cHhNaNf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "b1669d2b-f75f-4c95-bf53-1f713ecf14a6"
      },
      "source": [
        "df_train_ner.loc[df_train_ner['word_NER'] == 'PERSON'].word.value_counts().head(20)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bing bong bing bong                                        75\n",
              "obama                                                      45\n",
              "suppo                                                      35\n",
              "hillary                                                    35\n",
              "melancholy melancholymusic                                 31\n",
              "sta                                                        26\n",
              "bjp                                                        23\n",
              "feminismiscancer feminismisterrorism feminismmuktbharat    20\n",
              "hu                                                         18\n",
              "christina grimmie                                          18\n",
              "tgif ff                                                    18\n",
              "sea shepherd suppoers                                      17\n",
              "yoyoyou                                                    17\n",
              "gamedev indiedev indiegamedev                              17\n",
              "heabroken                                                  16\n",
              "lebron                                                     16\n",
              "jo cox                                                     16\n",
              "donald trump                                               15\n",
              "detoxdiet altwaystoheal                                    15\n",
              "boricua                                                    14\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNeZskK-mxZL",
        "colab_type": "text"
      },
      "source": [
        "## Наиболее обсуждаемые персоны в test датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaAzFwBchD3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "b6c605ac-94cd-4e75-f70f-46489eebdd7a"
      },
      "source": [
        "df_test_ner.loc[df_test_ner['word_NER'] == 'PERSON'].word.value_counts().head(20)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bing bong bing bong                                        32\n",
              "suppo                                                      31\n",
              "obama                                                      22\n",
              "feminismiscancer feminismisterrorism feminismmuktbharat    20\n",
              "sta                                                        19\n",
              "hillary                                                    13\n",
              "christina grimmie                                          12\n",
              "bjp                                                        11\n",
              "jo cox                                                     11\n",
              "jesus                                                      10\n",
              "lebron                                                     10\n",
              "regrann                                                    10\n",
              "donald trump                                                9\n",
              "clinton                                                     9\n",
              "melancholy melancholymusic                                  9\n",
              "th bihday                                                   9\n",
              "boricua                                                     8\n",
              "tgif ff                                                     8\n",
              "gamedev indiedev indiegamedev                               8\n",
              "sea shepherd suppoers                                       8\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DbLmA56nFyj",
        "colab_type": "text"
      },
      "source": [
        "## Наиболее обсуждаемые организации в train датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkiFjN1chPm2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "c93477fc-3d46-46ab-d424-4d56f79bd73f"
      },
      "source": [
        "df_train_ner.loc[df_train_ner['word_NER'] == 'ORG'].word.value_counts().head(20)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sjw                 73\n",
              "allahsoil           52\n",
              "gop                 51\n",
              "nba                 38\n",
              "islam               34\n",
              "cavs                30\n",
              "social analytics    27\n",
              "ht                  27\n",
              "wso                 26\n",
              "trump               26\n",
              "facebook            25\n",
              "cnn                 24\n",
              "google              21\n",
              "ios                 21\n",
              "bihday              18\n",
              "eu                  17\n",
              "house               15\n",
              "brexit              14\n",
              "obama               14\n",
              "bogota colombia     14\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu-n4IgJm7QG",
        "colab_type": "text"
      },
      "source": [
        "## Наиболее обсуждаемые организации в test датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjsyMkumhSbG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "25131e56-b91b-4511-b5d6-8ed9911621c8"
      },
      "source": [
        "df_test_ner.loc[df_test_ner['word_NER'] == 'ORG'].word.value_counts().head(20)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "allahsoil    31\n",
              "sjw          29\n",
              "gop          25\n",
              "trump        21\n",
              "bihday       20\n",
              "nba          20\n",
              "ht           17\n",
              "islam        16\n",
              "facebook     11\n",
              "obama        11\n",
              "amazon        9\n",
              "eu            9\n",
              "cnn           9\n",
              "cavs          9\n",
              "google        8\n",
              "fbi           8\n",
              "ios           8\n",
              "gbpusd        8\n",
              "vsco          8\n",
              "spo           8\n",
              "Name: word, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wwcUxBFGmBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJwpZ1OiJp-v",
        "colab_type": "text"
      },
      "source": [
        "### Задание 2.\n",
        "Используя библиотеку nltk, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? Для данного задания используем ограничение на количество символов во входном датасете (max_word_limit_spacy = 1000000), чтобы иметь возможность сравнить результаты работы Spacy и nltk. Обратите внимание, что nltk чувствителен к регистру.\n",
        "С помощью nltk выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMFC11FWn5no",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "c959a46d-9e14-4f1a-9651-13a1ebd3ffce"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxtX9oMfztus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nltk.pos_tag(nltk.word_tokenize(document))"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gBJ0PfjI-cl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34a84aff-a8fc-4987-81a2-a2ea13ad94ea"
      },
      "source": [
        "document = combine_df.clean_tweet.apply(lambda x: nlp(x)).to_string()\n",
        "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label') }"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMOLGylZJvVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZdRRvriJvOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5XCWrWqLPsQ",
        "colab_type": "text"
      },
      "source": [
        "### Задание 3.\n",
        "Какая из библиотек по вашему лучше отработала? Сравните качество полученных most_common NER и количество распознаных NER.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0BygxxHLSrh",
        "colab_type": "text"
      },
      "source": [
        "NLTK без результата"
      ]
    }
  ]
}